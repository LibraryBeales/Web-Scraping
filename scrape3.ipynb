{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by R. David Beales for the [Kelvin Smith Library](https://case.edu/library/) at [Case Western Reserve University](https://case.edu) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email rdb104@case.edu.<br />\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: Making a Request and Receiving a Response\n",
    "\n",
    "**Description:** This lesson explores how to collect multiple connected data points from a web page and store them in a csv file.  \n",
    "\n",
    "**Use Case:** For Learners (Additional explanation, not ideal for researchers)\n",
    "\n",
    "**Difficulty:** Beginner\n",
    "\n",
    "**Completion time:** 60 minutes\n",
    "\n",
    "**Knowledge Required:** Basic Python\n",
    "\n",
    "**Knowledge Recommended:** HTML Structure\n",
    "\n",
    "**Data Format:** `html`, `txt`, `py` \n",
    "\n",
    "**Libraries Used:** `requests` \n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project #3: Scraping sets of related information into CSV files.\n",
    "\n",
    "Build a scraper that collects multiple data points about each book based upon specific criteria.\n",
    "\n",
    "In this project you will:\n",
    "1. Determine what data we are able to collect about each book listed in the store.  \n",
    "2. Use the `Inspect` tool in your web browser to identify the web page struture for those pieces of data. \n",
    "3. Understand and use a python script to crawl the web page and extract only the data that meets the classification criteria we identified in steps 1 and 2.\n",
    "4. Write the data to a csv file. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What data is available?\n",
    "\n",
    "![title](img/booklisting.png)  If we look at this screenshot captured from the web page, we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests  #https://requests.readthedocs.io/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `requests` package has been imported we can use the various excellent methods that are built into the package. The most common method for web scraping is the `get` method.\n",
    "\n",
    "`requests.get` will send a `get` request to a web address that you specify.  This simple example will get everything from the web server at that url, but `requests` has powerful tools for selecting exactly what you want to scrape, which we will explore in a later lesson.\n",
    "\n",
    "Try running the code below.\n",
    "What response do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Fetch the page\n",
    "results = requests.get(\"https://books.toscrape.com/\")\n",
    "\n",
    "# 2.Get the page content and assign it to the varaible 'content'\n",
    "content = results.text\n",
    "\n",
    "# 3. Create the soup\n",
    "soup = BeautifulSoup(content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scrape.txt','w') as file:\n",
    "    file.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
